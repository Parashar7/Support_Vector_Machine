{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LAB7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Support Vector Machine\n"
      ],
      "metadata": {
        "id": "rXLjV0g24AxS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Technique (Support Vector Machine)\n",
        "\n",
        "Support Vector Machine or SVM is one of the most popular Supervised Learning algorithms, which is used for Classification as well as Regression problems. However, primarily, it is used for Classification problems in Machine Learning.\n",
        "\n",
        "The goal of the SVM algorithm is to create the best line or decision boundary that can segregate n-dimensional space into classes so that we can easily put the new data point in the correct category in the future. This best decision boundary is called a hyperplane."
      ],
      "metadata": {
        "id": "CgQHK1a34S-n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Problem\n",
        "SVM can be understood with the example that we have used in the KNN classifier. Suppose we see a strange cat that also has some features of dogs, so if we want a model that can accurately identify whether it is a cat or dog, so such a model can be created by using the SVM algorithm. We will first train our model with lots of images of cats and dogs so that it can learn about different features of cats and dogs, and then we test it with this strange creature."
      ],
      "metadata": {
        "id": "V1o31PSA4V5p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code"
      ],
      "metadata": {
        "id": "MPhvUnho44ho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import svm\n",
        "\n",
        "# Importing the Dataset\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
        "\n",
        "# Assign colum names to the dataset\n",
        "colnames = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class']\n",
        "\n",
        "# Read dataset to pandas dataframe\n",
        "irisdata = pd.read_csv(url, names=colnames)\n",
        "# Preprocessing\n",
        "\n",
        "print(irisdata.head())\n",
        "X = irisdata.drop('Class', axis=1)\n",
        "y = irisdata['Class']\n",
        "# Train Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkEzzO2k5JsD",
        "outputId": "a64ce473-fee9-4d8b-e1dd-0e954e9d17ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sepal-length  sepal-width  petal-length  petal-width        Class\n",
            "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
            "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
            "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
            "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
            "4           5.0          3.6           1.4          0.2  Iris-setosa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results For RBF Kernel"
      ],
      "metadata": {
        "id": "ewDeaJOn8lOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RBF Kernel\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svclassifier1 = SVC(kernel='rbf', degree=2)\n",
        "svclassifier1.fit(X_train, y_train)\n",
        "# Making Predictions\n",
        "y_pred = svclassifier1.predict(X_test)\n",
        "# Evaluating the Algorithm\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print('RBF Kernel Results:')\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHC7mbuJ8tU4",
        "outputId": "38c5dd82-5cc1-44c4-c0d5-e5a5f5c83721"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RBF Kernel Results:\n",
            "[[ 9  0  0]\n",
            " [ 0  9  2]\n",
            " [ 0  0 10]]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "    Iris-setosa       1.00      1.00      1.00         9\n",
            "Iris-versicolor       1.00      0.82      0.90        11\n",
            " Iris-virginica       0.83      1.00      0.91        10\n",
            "\n",
            "       accuracy                           0.93        30\n",
            "      macro avg       0.94      0.94      0.94        30\n",
            "   weighted avg       0.94      0.93      0.93        30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results for Polynomial Kernel"
      ],
      "metadata": {
        "id": "O8BvFznl8c_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Polynomial Kernel\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svclassifier = SVC(kernel='poly', degree=2)\n",
        "svclassifier.fit(X_train, y_train)\n",
        "# Making Predictions\n",
        "y_pred = svclassifier.predict(X_test)\n",
        "# Evaluating the Algorithm\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print('Polynomial Kernel Results:')\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guu4wqUx8hVt",
        "outputId": "2262f6c1-f685-4959-b1bc-aec591c3bd90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Polynomial Kernel Results:\n",
            "[[ 9  0  0]\n",
            " [ 0 11  0]\n",
            " [ 0  1  9]]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "    Iris-setosa       1.00      1.00      1.00         9\n",
            "Iris-versicolor       0.92      1.00      0.96        11\n",
            " Iris-virginica       1.00      0.90      0.95        10\n",
            "\n",
            "       accuracy                           0.97        30\n",
            "      macro avg       0.97      0.97      0.97        30\n",
            "   weighted avg       0.97      0.97      0.97        30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Result for Sigmoid Kernel"
      ],
      "metadata": {
        "id": "d5CZiJI27soM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sigmoid Kernel\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svclassifier2 = SVC(kernel='sigmoid', degree=2)\n",
        "svclassifier2.fit(X_train, y_train)\n",
        "# Making Predictions\n",
        "y_pred = svclassifier2.predict(X_test)\n",
        "\n",
        "# Evaluating the Algorithm\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print('Sigmoid Kernel Results:')\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IinDzOXu7u_s",
        "outputId": "51a610f0-3b7d-4cb2-d7c2-01581b462882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sigmoid Kernel Results:\n",
            "[[ 9  0  0]\n",
            " [11  0  0]\n",
            " [10  0  0]]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "    Iris-setosa       0.30      1.00      0.46         9\n",
            "Iris-versicolor       0.00      0.00      0.00        11\n",
            " Iris-virginica       0.00      0.00      0.00        10\n",
            "\n",
            "       accuracy                           0.30        30\n",
            "      macro avg       0.10      0.33      0.15        30\n",
            "   weighted avg       0.09      0.30      0.14        30\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab Assigned\n",
        "\n",
        "Apply SVM on new dataset spam.csv"
      ],
      "metadata": {
        "id": "wdFM3O0e67AD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code"
      ],
      "metadata": {
        "id": "tV1cbFbc7Er2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# New Data set\n",
        "\n",
        "# Assign colum names to the dataset\n",
        "colnames = ['label', 'message', 'petal_length', 'petal_width', 'Class']\n",
        "\n",
        "# Read dataset to pandas dataframe\n",
        "# from google.colab import files\n",
        "# upload = files.upload()\n",
        "df = pd.read_csv('spam.csv', names=colnames, encoding=\"ISO-8859-1\")\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "df.replace(np.nan,0, inplace=True)\n",
        "# print(df.petal_length.head())\n",
        "# print(df.head())\n",
        "\n",
        "# Preprocessing\n",
        "X = df['message'].values\n",
        "y = df['label'].values\n",
        "# Train Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state= 0)\n",
        "\n",
        "# Converting String to Integer\n",
        "cv = CountVectorizer()\n",
        "X_train = cv.fit_transform(X_train)\n",
        "X_test = cv.transform(X_test)\n",
        "\n",
        "# Polynomial Kernel\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svclassifier3 = SVC(kernel='poly', degree=2, random_state=0)\n",
        "svclassifier3.fit(X_train, y_train)\n",
        "# Making Predictions\n",
        "y_pred = svclassifier3.predict(X_test)\n",
        "# Evaluating the Algorithm\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print('Spam Polynomial Kernel Results:')\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# RBF Kernel\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svclassifier4 = SVC(kernel='rbf', random_state=0)\n",
        "svclassifier4.fit(X_train, y_train)\n",
        "# Making Predictions\n",
        "y_pred = svclassifier4.predict(X_test)\n",
        "# Evaluating the Algorithm\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print('Spam RBF Kernel Results:')\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Sigmoid Kernel\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svclassifier5 = SVC(kernel='sigmoid', degree=2)\n",
        "svclassifier5.fit(X_train, y_train)\n",
        "# Making Predictions\n",
        "y_pred = svclassifier5.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGb1sc-l7GVm",
        "outputId": "c6bcf89e-8474-422e-afcd-f483dc3514ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spam Polynomial Kernel Results:\n",
            "[[952   0]\n",
            " [ 38 125]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.96      1.00      0.98       952\n",
            "        spam       1.00      0.77      0.87       163\n",
            "\n",
            "    accuracy                           0.97      1115\n",
            "   macro avg       0.98      0.88      0.92      1115\n",
            "weighted avg       0.97      0.97      0.96      1115\n",
            "\n",
            "Spam RBF Kernel Results:\n",
            "[[950   2]\n",
            " [ 21 142]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.98      1.00      0.99       952\n",
            "        spam       0.99      0.87      0.93       163\n",
            "\n",
            "    accuracy                           0.98      1115\n",
            "   macro avg       0.98      0.93      0.96      1115\n",
            "weighted avg       0.98      0.98      0.98      1115\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion Matrix"
      ],
      "metadata": {
        "id": "2NCqtYQN7KQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print('Spam Sigmoid Kernel Results:')\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdrbY_oS7PZ2",
        "outputId": "229e0a8f-078b-4e57-a992-a2fc499a6f78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spam Sigmoid Kernel Results:\n",
            "[[927  25]\n",
            " [ 38 125]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.96      0.97      0.97       952\n",
            "        spam       0.83      0.77      0.80       163\n",
            "\n",
            "    accuracy                           0.94      1115\n",
            "   macro avg       0.90      0.87      0.88      1115\n",
            "weighted avg       0.94      0.94      0.94      1115\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Result"
      ],
      "metadata": {
        "id": "VjNpP25U7UY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('RBF Kernel',svclassifier4.score(X_test, y_test))\n",
        "\n",
        "print('Polynomial Kernel',svclassifier3.score(X_test, y_test))\n",
        "\n",
        "print('Sigmodial Kernal', svclassifier5.score(X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5-3zWMb7W_7",
        "outputId": "de314251-c4c7-423f-ad7d-7eee984fb508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RBF Kernel 0.979372197309417\n",
            "Polynomial Kernel 0.9659192825112107\n",
            "Sigmodial Kernal 0.9434977578475336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "\n",
        "The method of support vector machines as an alternative to the conservative logistic regression models was studied and its performance compared on the real credit data sets. Especially in combination with the non-linear kernel, SVM proved itself as a competitive approach and provided a slight edge on top of the logistic regression model."
      ],
      "metadata": {
        "id": "HNbDJeubAY_k"
      }
    }
  ]
}